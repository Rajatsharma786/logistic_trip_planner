{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fbbce2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, timeout=60, max_retries=8)\n",
    "summarizer = chatgpt.bind(max_tokens=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a66f648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"o200k_base\")\n",
    "def clamp_tokens(text: str, max_tokens: int) -> str:\n",
    "\ttoks = enc.encode(text)\n",
    "\tif len(toks) <= max_tokens:\n",
    "\t\treturn text\n",
    "\tout = enc.decode(toks[:max_tokens])\n",
    "\tcut = max(out.rfind(\". \"), out.rfind(\"\\n\"), out.rfind(\" \"))\n",
    "\tif cut > 0:\n",
    "\t\tout = out[:cut+1]\n",
    "\treturn out + \" …\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cfef3fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(8))\n",
    "def summarize_chunk(chunk_text: str, title: str | None = None, page: int | None = None) -> str:\n",
    "\tprefix = f\"Title: {title}\\nPage: {page}\\n\" if title is not None else \"\"\n",
    "\tprompt_tmpl = ChatPromptTemplate.from_template(\n",
    "\t\t\"You are an assistant for road-work document analysis.\\n\"\n",
    "\t\t\"Summarize the following chunk in 2–3 sentences, suitable for retrieval context.\\n\"\n",
    "\t\t\"Be specific (places, programs, dates), avoid generalities, no hallucinations.\\n\\n\"\n",
    "\t\t\"{pref}Chunk:\\n{chunk}\\n\\nSummary:\"\n",
    "\t)\n",
    "\tchain = prompt_tmpl | summarizer | StrOutputParser()\n",
    "\t# clamp the prompt input so each call has predictable token size\n",
    "\treturn chain.invoke({\"pref\": prefix, \"chunk\": clamp_tokens(chunk_text, 2000)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "972c626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(8))\n",
    "# def generate_chunk_context(paper_context: str, chunk: str) -> str:\n",
    "#     prompt_tmpl = ChatPromptTemplate.from_template(\n",
    "#         \"You are an AI assistant for road-work paper analysis.\\n\"\n",
    "#         \"Using the summary and compressed document below, provide a brief 2–3 sentence context for the chunk.\\n\\n\"\n",
    "#         \"{paper}\\n\\nChunk:\\n{chunk}\\n\\nContext:\"\n",
    "#     )\n",
    "#     chain = prompt_tmpl | chatgpt | StrOutputParser()\n",
    "#     return chain.invoke({\"paper\": clamp_tokens(paper_context, 5200), \"chunk\": chunk})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58c406b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "import time,uuid\n",
    "\n",
    "def create_contextual_chunks(file_path, chunk_size=2000, chunk_overlap=200, neighbor_chars=300, throttle_s=0.25):\n",
    "\t# load + split\n",
    "\tloader = PyMuPDFLoader(file_path)\n",
    "\tdoc_pages = loader.load()\n",
    "\tsplitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "\tdoc_chunks = splitter.split_documents(doc_pages)\n",
    "\n",
    "\tcontextual_chunks = []\n",
    "\tn = len(doc_chunks)\n",
    "\tfor i, chunk in enumerate(doc_chunks):\n",
    "\t\ttext = chunk.page_content\n",
    "\n",
    "\t\t# optional small neighbor window (keeps chunk-first, adds coherence without big token cost)\n",
    "\t\tif neighbor_chars and n > 1:\n",
    "\t\t\tprev_txt = doc_chunks[i-1].page_content[-neighbor_chars:] if i > 0 else \"\"\n",
    "\t\t\tnext_txt = doc_chunks[i+1].page_content[:neighbor_chars] if i+1 < n else \"\"\n",
    "\t\t\tif prev_txt:\n",
    "\t\t\t\ttext = f\"(Prev) {prev_txt}\\n\\n{chunk.page_content}\"\n",
    "\t\t\tif next_txt:\n",
    "\t\t\t\ttext = f\"{text}\\n\\n(Next) {next_txt}\"\n",
    "\n",
    "\t\tmeta = {\n",
    "\t\t\t'id': str(uuid.uuid4()),\n",
    "\t\t\t'page': chunk.metadata.get('page'),\n",
    "\t\t\t'source': chunk.metadata.get('source'),\n",
    "\t\t\t'title': chunk.metadata.get('source', '').split('/')[-1]\n",
    "\t\t}\n",
    "\t\tsummary = summarize_chunk(text, title=meta['title'], page=meta['page'])\n",
    "\n",
    "\t\t# store both: prepend summary to content for embedding; also keep in metadata\n",
    "\t\tcontextual_chunks.append(\n",
    "\t\t\tDocument(\n",
    "\t\t\t\tpage_content=f\"{summary}\\n\\n{chunk.page_content}\",\n",
    "\t\t\t\tmetadata={**meta, \"chunk_summary\": summary}\n",
    "\t\t\t)\n",
    "\t\t)\n",
    "\t\ttime.sleep(throttle_s)  # smooth TPM\n",
    "\treturn contextual_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "920d99ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\DELL\\\\Desktop\\\\AI Projects\\\\Langchain_proj\\\\Logistic_Agent_Planner\\\\data\\\\road_knowledge\\\\Chapter-2-Project-Rationale.pdf',\n",
       " 'C:\\\\Users\\\\DELL\\\\Desktop\\\\AI Projects\\\\Langchain_proj\\\\Logistic_Agent_Planner\\\\data\\\\road_knowledge\\\\Hume-Region-Planning-for-Freight-Pilot-Strategy-Report.pdf',\n",
       " 'C:\\\\Users\\\\DELL\\\\Desktop\\\\AI Projects\\\\Langchain_proj\\\\Logistic_Agent_Planner\\\\data\\\\road_knowledge\\\\Hume-Regional-Growth-Plan-May-2014.pdf']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "pdf_files = glob(r'C:\\Users\\DELL\\Desktop\\AI Projects\\Langchain_proj\\Logistic_Agent_Planner\\data\\road_knowledge\\*.pdf')\n",
    "pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff7fa4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Connection Test: content=\"Hello! Yes, I'm here and ready to help. What can I assist you with today?\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 13, 'total_tokens': 32, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C6b2FrO51MslxKCGMK83ft7PbmFNG', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--c9cf4ca4-1cd1-4e2d-9af9-73f13f2ff4ad-0' usage_metadata={'input_tokens': 13, 'output_tokens': 19, 'total_tokens': 32, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    chatgpt = ChatOpenAI(\n",
    "        model_name=\"gpt-4o-mini\",  # Changed from \"gpt-4o-mini\" to a valid model name\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    # Test the connection with a simple prompt\n",
    "    test_response = chatgpt.invoke(\"Hello, are you working?\")\n",
    "    print(\"API Connection Test:\", test_response)\n",
    "except Exception as e:\n",
    "    print(f\"API Connection Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e78fde7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\DELL\\Desktop\\AI Projects\\Langchain_proj\\Logistic_Agent_Planner\\data\\road_knowledge\\Chapter-2-Project-Rationale.pdf\n",
      "Successfully processed 52 chunks\n",
      "Processing file: C:\\Users\\DELL\\Desktop\\AI Projects\\Langchain_proj\\Logistic_Agent_Planner\\data\\road_knowledge\\Hume-Region-Planning-for-Freight-Pilot-Strategy-Report.pdf\n",
      "Successfully processed 123 chunks\n",
      "Processing file: C:\\Users\\DELL\\Desktop\\AI Projects\\Langchain_proj\\Logistic_Agent_Planner\\data\\road_knowledge\\Hume-Regional-Growth-Plan-May-2014.pdf\n",
      "Successfully processed 182 chunks\n"
     ]
    }
   ],
   "source": [
    "paper_docs = []\n",
    "for fp in pdf_files:\n",
    "    try:\n",
    "        print(f\"Processing file: {fp}\")\n",
    "        chunks = create_contextual_chunks(file_path=fp)\n",
    "        if chunks:  # Only extend if we got valid chunks\n",
    "            paper_docs.extend(chunks)\n",
    "            print(f\"Successfully processed {len(chunks)} chunks\")\n",
    "        else:\n",
    "            print(f\"No chunks were generated for {fp}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {fp}: {str(e)}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "828fefab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# details here: https://openai.com/blog/new-embedding-models-and-api-updates\n",
    "openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "476499a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "chroma_db = Chroma.from_documents(documents=paper_docs,\n",
    "                                  collection_name='my_context_db',\n",
    "                                  embedding=openai_embed_model,\n",
    "                                  # need to set the distance function to cosine else it uses euclidean by default\n",
    "                                  # check https://docs.trychroma.com/guides#changing-the-distance-function\n",
    "                                  collection_metadata={\"hnsw:space\": \"cosine\"},\n",
    "                                  persist_directory=\"./my_context_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5a9cec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_db = Chroma(persist_directory=\"./my_context_db\",\n",
    "                   collection_name='my_context_db',\n",
    "                   embedding_function=openai_embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5167f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_retriever = chroma_db.as_retriever(search_type=\"similarity\",\n",
    "                                              search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30361b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "rag_prompt = \"\"\"You are an assistant who is an expert in question-answering tasks.\n",
    "                Answer the following question using only the following pieces of retrieved context.\n",
    "                If the answer is not in the context, do not make up answers, just say that you don't know.\n",
    "                Keep the answer detailed and well formatted based on the information from the context.\n",
    "\n",
    "                Question:\n",
    "                {question}\n",
    "\n",
    "                Context:\n",
    "                {context}\n",
    "\n",
    "                Answer:\n",
    "            \"\"\"\n",
    "\n",
    "rag_prompt_template = ChatPromptTemplate.from_template(rag_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "53d83e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "qa_rag_chain = (\n",
    "    {\n",
    "        \"context\": (similarity_retriever\n",
    "                      |\n",
    "                    format_docs),\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "      |\n",
    "    rag_prompt_template\n",
    "      |\n",
    "    chatgpt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0daf53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "When traveling to Sydney via the Hume route to deliver goods, there are several important considerations to keep in mind:\n",
       "\n",
       "1. **Freight Corridors**: The Hume region serves as a critical corridor for freight movement in Australia, connecting major cities such as Melbourne, Sydney, and Brisbane. Understanding the significance of these corridors can help in planning your route effectively.\n",
       "\n",
       "2. **Road and Rail Linkages**: The region has intensive management and investment in road and rail linkages to regional NSW and Queensland. Familiarize yourself with the key freight corridors, such as the Murray River and localities like Tocumwal, Wodonga, and Shepparton, which are essential for enhancing regional freight efficiency.\n",
       "\n",
       "3. **Preferred Access Routes**: Utilize preferred access route maps for industrial and commercial precincts. These maps can assist in avoiding road space conflicts, minimizing localized congestion, and reducing wear on local roads.\n",
       "\n",
       "4. **State-Managed Roads**: Prioritize state-managed roads over local routes due to limited funding and maintenance issues. This is crucial for ensuring that heavy vehicles have access to well-maintained routes.\n",
       "\n",
       "5. **Rest Areas**: Be aware that there are 165 recorded rest areas along A and B roads, but only 35 are designated for truck parking. Plan your stops accordingly to ensure compliance with rest regulations and to avoid fatigue.\n",
       "\n",
       "6. **Freight Management Solutions**: Collaborate with local councils and freight generators to understand the costs and benefits of route upgrades and maintenance. This collaboration can lead to better freight management solutions and improved delivery efficiency.\n",
       "\n",
       "7. **Topography Considerations**: The topography of the Hume region can affect freight movement. Be prepared for variations in route conditions, especially in areas with alpine valleys or dispersed freight movement patterns.\n",
       "\n",
       "8. **Future Infrastructure Developments**: Stay informed about ongoing and future infrastructure projects, such as the proposed high-speed rail system and upgrades to existing transport networks, which may impact your travel and delivery times.\n",
       "\n",
       "By keeping these factors in mind, you can optimize your journey and ensure a successful delivery of goods to Sydney via the Hume route."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "query = \"Travelling to sydney via hume route to deliver goods what should I keep in mind \"\n",
    "result = qa_rag_chain.invoke(query)\n",
    "display(Markdown(result.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b264a2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
